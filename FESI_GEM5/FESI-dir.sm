/**
 * This file contains the directory controller of the FESI protocol
 *
 * In Ruby the directory controller both contains the directory coherence state
 * but also functions as the memory controller in many ways. There are states
 * in the directory that are both memory-centric and cache-centric.
 *
 * The protocol in this file is based off of the novel FESI protocol
 *
 * Authors: Rishabh Chitoor
 */

machine(MachineType:Directory, "FESI 1 Level Directory protocol")
    :
      // This "DirectoryMemory" is a little weird. It is initially allocated
      // so that it *can* cover all of memory (i.e., there are pointers for
      // every 64-byte block in memory). However, the entries are lazily
      // created in getDirEntry()
      DirectoryMemory * directory;
      // You can put any parameters you want here. They will be exported as
      // normal SimObject parameters (like in the SimObject description file)
      // and you can set these parameters at runtime via the python config
      // file. If there is no default here (like directory), it is mandatory
      // to set the parameter in the python config. Otherwise, it uses the
      // default value set here.
      Cycles toMemLatency := 1;

    // Forwarding requests from the directory *to* the caches.
    MessageBuffer *forwardToCache, network="To", virtual_network="1",
          vnet_type="forward";
    // Response from the directory *to* the cache.
    MessageBuffer *responseToCache, network="To", virtual_network="2",
          vnet_type="response";

    // Requests *from* the cache to the directory
    MessageBuffer *requestFromCache, network="From", virtual_network="0",
          vnet_type="request";

    // Responses *from* the cache to the directory
    MessageBuffer *responseFromCache, network="From", virtual_network="2",
          vnet_type="response";

    // Special buffer for memory requests. Kind of like the mandatory queue
    MessageBuffer *requestToMemory;

    // Special buffer for memory responses. Kind of like the mandatory queue
    MessageBuffer *responseFromMemory;

{
    // For many thins in SLICC you can specify a default. However, this default
    // must use the C++ name (mangled SLICC name). For the state below you have
    // to use the controller name and the name we use for states.
    state_declaration(State, desc="Directory states", default="Directory_State_I") {
        // Stable states.
        // NOTE: Thise are "cache-centric" states like in Sorin et al.
        // However, The access permissions are memory-centric.
        I, AccessPermission:Read_Write,	desc="Invalid in the caches.";
        E, AccessPermission:Invalid,	desc="Exactly one cache has the blk";
        F, AccessPermission:Maybe_Stale, desc="One of the caches has the block in F state";

        // Transient states
        F_AS, AccessPermission:Busy,	desc="Replacing F, need to find new F, waiting for some S to accept";
	FF_A, AccessPermission:Busy,	desc="Sent command for S to F, waiting for ack";

        // Waiting for data from memory
        //S_m, AccessPermission:Read_Write, desc="In S waiting for mem"; NOT NEEDED
        F_m, AccessPermission:Read_Write, desc="Moving to F waiting for mem"; // Need to send Data
	E_m, AccessPermission:Read_Write, desc="Moving to E waiting for mem"; // Need to send Exclusive Data

        // Waiting for write-ack from memory
        FI_m, AccessPermission:Busy,	desc="Moving from F to I waiting for ack";
    }

    enumeration(Event, desc="Directory events") {
        // Data requests from the cache
        GetS,			desc="Request for read-only data from cache";
        GetMNonOwner,		desc="Request for write data from non-Owner";
	GetMOwner,		desc="Request for write data from the Owner";

        // Writeback requests from the cache
        PutSSharer,     	desc="PutS and the block is in Sharer list";
	PutSNonSharer,		desc="PutS and the block is not in Sharer list"; // to ease implementation
        PutFOwnerSharer,	desc="Dirty data writeback from the owner with atleast 1 sharer";
	PutFOwnerNoSharer,	desc="Dirty data writeback from the owner with no sharer"; // to ease implementation
        PutFNonOwner,		desc="Dirty data writeback from non-owner";
	PutEOwner,		desc="Clean data writeback from owner";
	PutENonOwner,		desc="Clean data writeback from non-owner";

        // Cache responses
	StoFAck,		desc="Sharer is ready to move to F";
	StoFInvAck,		desc="Sharer cannot move to F because it is getting replaced";
	LastStoFInvAck,		desc="To ease implementation, last StoFInvAck"; // to ease implementation
	SFDone,			desc="Sharer has succesfully moved to F";

        // From Memory
        MemData,		desc="Data from memory";
        MemAck,			desc="Ack from memory that write is complete";
    }

    // NOTE: We use a netdest for the sharers and the owner so we can simply
    // copy the structure into the message we send as a response.
    structure(Entry, desc="...", interface="AbstractCacheEntry", main="false") {
        State DirState,         desc="Directory state";
        NetDest Sharers,        desc="Sharers for this block";
        NetDest Owner,          desc="Owner of this block";
    }

    Tick clockEdge();

    // This either returns the valid directory entry, or, if it hasn't been
    // allocated yet, this allocates the entry. This may save some host memory
    // since this is lazily populated.
    Entry getDirectoryEntry(Addr addr), return_by_pointer = "yes" {
        Entry dir_entry := static_cast(Entry, "pointer", directory[addr]);
        if (is_invalid(dir_entry)) {
            // This first time we see this address allocate an entry for it.
            dir_entry := static_cast(Entry, "pointer",
                                     directory.allocate(addr, new Entry));
        }
        return dir_entry;
    }

    /*************************************************************************/
    // Functions that we need to define/override to use our specific structures
    // in this implementation.
    // NOTE: we don't have TBE in this machine, so we don't need to pass it
    // to these overridden functions.

    State getState(Addr addr) {
        if (directory.isPresent(addr)) {
            return getDirectoryEntry(addr).DirState;
        } else {
            return State:I;
        }
    }

    void setState(Addr addr, State state) {
        if (directory.isPresent(addr)) {    
            getDirectoryEntry(addr).DirState := state;            
        }
    }

    // This is really the access permissions of memory.
    // TODO: I don't understand this at the directory.
    AccessPermission getAccessPermission(Addr addr) {
        if (directory.isPresent(addr)) {
            Entry e := getDirectoryEntry(addr);
            return Directory_State_to_permission(e.DirState);
        } else  {
            return AccessPermission:NotPresent;
        }
    }
    void setAccessPermission(Addr addr, State state) {
        if (directory.isPresent(addr)) {
            Entry e := getDirectoryEntry(addr);
            e.changePermission(Directory_State_to_permission(state));
        }
    }

    void functionalRead(Addr addr, Packet *pkt) {
        functionalMemoryRead(pkt);
    }

    // This returns the number of writes. So, if we write then return 1
    int functionalWrite(Addr addr, Packet *pkt) {
        if (functionalMemoryWrite(pkt)) {
            return 1;
        } else {
            return 0;
        }
    }


    /*************************************************************************/
    // Network ports

    out_port(forward_out, RequestMsg, forwardToCache);
    out_port(response_out, ResponseMsg, responseToCache);
    out_port(memQueue_out, MemoryMsg, requestToMemory);

    in_port(memQueue_in, MemoryMsg, responseFromMemory) {
        if (memQueue_in.isReady(clockEdge())) {
            peek(memQueue_in, MemoryMsg) {
                if (in_msg.Type == MemoryRequestType:MEMORY_READ) {
                    trigger(Event:MemData, in_msg.addr);
                } else if (in_msg.Type == MemoryRequestType:MEMORY_WB) {
                    trigger(Event:MemAck, in_msg.addr);
                } else {
                    error("Invalid message");
                }
            }
        }
    }

    in_port(response_in, ResponseMsg, responseFromCache) {
        if (response_in.isReady(clockEdge())) {
            peek(response_in, ResponseMsg) {
		if (in_msg.Type == CoherenceResponseType:StoFAck) {
                    trigger(Event:StoFAck, in_msg.addr);
                } else if (in_msg.Type == CoherenceResponseType:StoFInvAck) {
		    Entry e := getDirectoryEntry(in_msg.addr);
		    assert(is_valid(e));
		    if(e.Sharers.count() == 1) {
			assert(e.Sharers.isElement(in_msg.Sender)); // has to be true
			trigger(Event:LastStoFInvAck, in_msg.addr);
		    } else {
			trigger(Event:StoFInvAck, in_msg.addr);
		    }		    
                } else if (in_msg.Type == CoherenceResponseType:SFDone) {
		    trigger(Event:SFDone, in_msg.addr);
		} else {
		    error("Unexpected Response");
		}
            }
        }
    }

    in_port(request_in, RequestMsg, requestFromCache) {
        if (request_in.isReady(clockEdge())) {
            peek(request_in, RequestMsg) {
                Entry e := getDirectoryEntry(in_msg.addr);
                if (in_msg.Type == CoherenceRequestType:GetS) {
                    trigger(Event:GetS, in_msg.addr);
                } else if (in_msg.Type == CoherenceRequestType:GetM) {
		    if (e.Owner.isElement(in_msg.Requestor)) {
			trigger(Event:GetMOwner, in_msg.addr);
		    } else {
			trigger(Event:GetMNonOwner, in_msg.addr);
		    }
                } else if (in_msg.Type == CoherenceRequestType:PutS) {
                    // If the Requestor is a sharer
		    assert(is_valid(e));
                    if (e.Sharers.isElement(in_msg.Requestor)) {
                    	trigger(Event:PutSSharer, in_msg.addr);
                    } else {
                        trigger(Event:PutSNonSharer, in_msg.addr);
                    }
                } else if (in_msg.Type == CoherenceRequestType:PutE) {
                    if (e.Owner.isElement(in_msg.Requestor)) { // USE LIKE THIS TO CHECK IF SHARER
                        trigger(Event:PutEOwner, in_msg.addr);
                    } else {
                        trigger(Event:PutENonOwner, in_msg.addr);
                    }
                } else if (in_msg.Type == CoherenceRequestType:PutF) {
                    assert(is_valid(e));
                    if (e.Owner.isElement(in_msg.Requestor)) { // USE LIKE THIS TO CHECK IF SHARER
			if (e.Sharers.count() == 0) {
                    	    trigger(Event:PutFOwnerNoSharer, in_msg.addr);
			} else {
			    trigger(Event:PutFOwnerSharer, in_msg.addr);
			}
                    } else {
                        trigger(Event:PutFNonOwner, in_msg.addr);
                    }
                } else {
                    error("Unexpected message type.");
                }
            }
        }
    }



    /*************************************************************************/
    // Actions

    // Memory actions.

    action(sendMemRead, "r", desc="Send a memory read request") {
        peek(request_in, RequestMsg) {
            // Send request through special memory request queue. At some
            // point the response will be on the memory response queue.
            // Like enqueue, this takes a latency for the request.
            enqueue(memQueue_out, MemoryMsg, toMemLatency) {
                out_msg.addr := address;
                out_msg.Type := MemoryRequestType:MEMORY_READ;
                out_msg.Sender := in_msg.Requestor;
                out_msg.MessageSize := MessageSizeType:Request_Control;
                out_msg.Len := 0;
            }
        }
    }

    action(sendDataToMem, "w", desc="Write data to memory") { // can use Requestor because I don't pop the request queue
        peek(request_in, RequestMsg) {
            DPRINTF(RubySlicc, "Writing memory for %#x\n", address);
            DPRINTF(RubySlicc, "Writing %s\n", in_msg.DataBlk);
            enqueue(memQueue_out, MemoryMsg, toMemLatency) {
                out_msg.addr := address;
                out_msg.Type := MemoryRequestType:MEMORY_WB;
                out_msg.Sender := in_msg.Requestor;
                out_msg.MessageSize := MessageSizeType:Writeback_Data;
                out_msg.DataBlk := in_msg.DataBlk;
                out_msg.Len := 0;
            }
        }
    }

    // Sharer/owner actions

// NOT NEEDED IN FESI actually
// -------------------------------------------------------------------------------
    action(addReqToSharers, "aS", desc="Add requestor to sharer list") {
        peek(request_in, RequestMsg) {
            getDirectoryEntry(address).Sharers.add(in_msg.Requestor);
        }
    }
// -------------------------------------------------------------------------------

    action(setRequestorOwner, "sQO", desc="Set the requestor as owner") {
        peek(request_in, RequestMsg) {
            getDirectoryEntry(address).Owner.add(in_msg.Requestor);
        }
    }

    // NEW ACTION exclusively for my protocol
    action(setResponderOwner, "sSO", desc="Set the responder as owner") {
        peek(response_in, ResponseMsg) {
            getDirectoryEntry(address).Owner.add(in_msg.Sender);
        }
    }

    action(addOwnerToSharers, "oS", desc="Add the owner to sharers") {
        Entry e := getDirectoryEntry(address);
        assert(e.Owner.count() == 1);
        e.Sharers.addNetDest(e.Owner);
    }

    action(removeReqFromSharers, "rQS", desc="Remove requestor from sharers") {
        peek(request_in, RequestMsg) {
            getDirectoryEntry(address).Sharers.remove(in_msg.Requestor);
        }
    }

    // NEW ACTION exclusively for my protocol
    action(removeResFromSharers, "rSS", desc="Remove responder from sharers") {
        peek(response_in, ResponseMsg) {
            getDirectoryEntry(address).Sharers.remove(in_msg.Sender);
        }
    }

    action(clearSharers, "cS", desc="Clear the sharer list") {
        getDirectoryEntry(address).Sharers.clear();
    }

    action(clearOwner, "cO", desc="Clear the owner") {
        getDirectoryEntry(address).Owner.clear();
    }

    // Invalidates and forwards

    action(sendInvToSharers, "i", desc="Send invalidate to all sharers") {
        peek(request_in, RequestMsg) {
            enqueue(forward_out, RequestMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceRequestType:Inv;
                out_msg.Requestor := in_msg.Requestor;
                out_msg.Destination := getDirectoryEntry(address).Sharers;
                out_msg.MessageSize := MessageSizeType:Control;
            }
        }
    }

    // need to send along with number of acks since it will send to the requestor; Acks = 0 always
    action(sendFwdGetS, "fS", desc="Send forward getS to owner") {
        assert(getDirectoryEntry(address).Owner.count() == 1);
        peek(request_in, RequestMsg) {
            enqueue(forward_out, RequestMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceRequestType:GetS;
                out_msg.Requestor := in_msg.Requestor;
                out_msg.Destination := getDirectoryEntry(address).Owner;
                out_msg.MessageSize := MessageSizeType:Control;
		out_msg.Acks := 0;
            }
        }
    }

    // sendFwdGetM can send the number of acks along to the Owner
    action(sendFwdGetM, "fM", desc="Send forward getM to owner") {
        assert(getDirectoryEntry(address).Owner.count() == 1);
        peek(request_in, RequestMsg) {
            enqueue(forward_out, RequestMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceRequestType:GetM;
                out_msg.Requestor := in_msg.Requestor;
                out_msg.Destination := getDirectoryEntry(address).Owner;
                out_msg.MessageSize := MessageSizeType:Control;
		// number of sharers is number of acks
                Entry e := getDirectoryEntry(address);
                out_msg.Acks := e.Sharers.count();
		assert(out_msg.Acks >= 0);
            }
        }
    }

    // Forward requests related to allocating F

    action(sendFAllocReq, "fAR", desc="Send FAllocReq to all sharers") {
        enqueue(forward_out, RequestMsg, 1) {
	    out_msg.addr := address;
	    out_msg.Type := CoherenceRequestType:FAllocReq;
	    out_msg.Requestor := machineID;
	    out_msg.Destination := getDirectoryEntry(address).Sharers;
	    out_msg.MessageSize := MessageSizeType:Control;
        }
    }

    action(sendAllocF, "aF", desc="send AllocF command to responder") {
        peek(response_in, ResponseMsg) {
            enqueue(forward_out, RequestMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceRequestType:AllocF;
                out_msg.Requestor := machineID;
                out_msg.Destination.add(in_msg.Sender);
                out_msg.MessageSize := MessageSizeType:Control;
            }
        }
    }

    // Responses to requests

    // This also needs to send along the number of sharers!!!!
    action(sendDataToReq, "d", desc="Send data from memory to requestor. ") {
                                    //"May need to send sharer number, too") 
        peek(memQueue_in, MemoryMsg) {
            enqueue(response_out, ResponseMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceResponseType:Data;
                out_msg.Sender := machineID;
                out_msg.Destination.add(in_msg.OriginalRequestorMachId); // this is what enables us to POP Requestor early
                out_msg.DataBlk := in_msg.DataBlk;
                out_msg.MessageSize := MessageSizeType:Data;
                out_msg.Acks := 0; // Dir will always send Acks=0 in response
            }
        }
    }

    action(sendExclusiveDataToReq, "Ed", desc="Send exclusive data from memory to requestor. ") {
        peek(memQueue_in, MemoryMsg) {
            enqueue(response_out, ResponseMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceResponseType:ExclusiveData;
                out_msg.Sender := machineID;
                out_msg.Destination.add(in_msg.OriginalRequestorMachId);
                out_msg.DataBlk := in_msg.DataBlk;
                out_msg.MessageSize := MessageSizeType:Data;
                out_msg.Acks := 0; // acks will be 0 for Exclusive data
            }
        }
    }

    action(sendPutAck, "a", desc="Send the put ack") {
        peek(request_in, RequestMsg) {
            enqueue(forward_out, RequestMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceRequestType:PutAck;
                out_msg.Requestor := machineID;
                out_msg.Destination.add(in_msg.Requestor);
                out_msg.MessageSize := MessageSizeType:Control;
            }
        }
    }

    action(sendAckCount, "ac", desc="Send the ack count to requestor") {
        peek(request_in, RequestMsg) {
            enqueue(response_out, ResponseMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceResponseType:AckCount;
                out_msg.Sender := machineID;
                out_msg.Destination.add(in_msg.Requestor);
                out_msg.MessageSize := MessageSizeType:Control;
		// number of sharers is number of acks
                Entry e := getDirectoryEntry(address);
                out_msg.Acks := e.Sharers.count();
		assert(out_msg.Acks >= 0);
            }
        }
    }

    // Queue management

    action(popResponseQueue, "pR", desc="Pop the response queue") {
        response_in.dequeue(clockEdge());
    }

    action(popRequestQueue, "pQ", desc="Pop the request queue") {
        request_in.dequeue(clockEdge());
    }

    action(popMemQueue, "pM", desc="Pop the memory queue") {
        memQueue_in.dequeue(clockEdge());
    }

    // Stalling actions
    action(stall, "z", desc="Stall the incoming request") {
        // Do nothing.
    }


    /*************************************************************************/
    // transitions

// ----------------------------------------
// I row transitions
// ----------------------------------------

    transition(I, GetS, E_m) {
        sendMemRead;
        setRequestorOwner;
        popRequestQueue;
    }

    transition(E_m, MemData, E) {
        sendExclusiveDataToReq;
        popMemQueue;
    }

    transition({I, E}, {PutSSharer, PutSNonSharer, PutENonOwner, PutFNonOwner}) {
        sendPutAck;
        popRequestQueue;
    }    

    transition(I, GetMNonOwner, F_m) {
        sendMemRead;
        setRequestorOwner;
        popRequestQueue;
    }

    transition(F_m, MemData, F) {
        sendDataToReq;
        clearSharers; // NOTE: This isn't *required* in some cases.
        popMemQueue;
    }

// -------------------------------
// E row transitions
// -------------------------------

    transition(E, GetS, F) {
        sendFwdGetS;
	addOwnerToSharers;
        clearOwner;
        setRequestorOwner;
        popRequestQueue;
    }

    transition(E, GetMNonOwner, F) {
        sendFwdGetM;
        clearOwner;
	setRequestorOwner;
        popRequestQueue;
    }

    transition(E, GetMOwner) {
        sendAckCount;
        popRequestQueue;
    }

    transition({E, F}, PutFOwnerNoSharer, FI_m) {
	sendDataToMem;
	clearOwner;
	sendPutAck;
	popRequestQueue;
    }

    transition(FI_m, MemAck, I) {
	popMemQueue;
    }

    transition(E, PutEOwner, I) {
	clearOwner;
	sendPutAck;
	popRequestQueue;
    }

// -----------------------------------------
// F row transitions
// -----------------------------------------

    transition(F, GetS) {
        sendFwdGetS;
        addOwnerToSharers;
        clearOwner;
	setRequestorOwner;
        popRequestQueue;
    }

    transition(F, GetMNonOwner) {
	removeReqFromSharers;
        sendFwdGetM; // sends the AcksCount to owner after subtracting the requestor from the sharers
        clearOwner; // can clear the owner once we send the fwdGetM
	setRequestorOwner; // set requestor as owner
	sendInvToSharers; // send invalidations to all sharers AFTER removing requestor from list of sharers
	clearSharers;     // can safely clear the sharers now
        popRequestQueue;
    }

    transition(F, GetMOwner) {
        sendAckCount;
        sendInvToSharers;
	clearSharers;
        popRequestQueue;
    }

    transition(F, {PutSSharer, PutENonOwner, PutFNonOwner}) {
	removeReqFromSharers;
	sendPutAck;
	popRequestQueue;
    }

    transition(F, PutSNonSharer) {
	sendPutAck;
	popRequestQueue;
    }

    transition(F, PutFOwnerSharer, F_AS) { // NOTE: I DON'T pop the request queue since allocation yet to be done
	clearOwner;
	sendFAllocReq;
    }

    transition(F, {StoFAck, StoFInvAck, LastStoFInvAck}) {
	popResponseQueue;
    }

// -----------------------------------------
// F_AS row transitions
// -----------------------------------------

    transition(F_AS, StoFAck, FF_A) {
	setResponderOwner;
	removeResFromSharers;
	sendAllocF;
	popResponseQueue;
    }
    
    transition(F_AS, StoFInvAck) {
	removeResFromSharers;
	popResponseQueue;
    }

    transition(F_AS, LastStoFInvAck, FI_m) {
	sendDataToMem;
	clearSharers;	
	sendPutAck;
	popRequestQueue; // since putAck has been sent
	popResponseQueue;	
    }

    // FI_m to I already done above

// -----------------------------------------
// FF_A row transitions
// -----------------------------------------

    transition(FF_A, {StoFAck, StoFInvAck, LastStoFInvAck}) {
	popResponseQueue;
    }

    transition(FF_A, SFDone, F) {
	sendPutAck;
	popRequestQueue; // since putAck has been sent
	popResponseQueue;	
    }

// -----------------------------------------
// Memory state transitions
// -----------------------------------------

    transition({FI_m, E_m, F_m}, {PutSSharer, PutSNonSharer, PutFNonOwner, PutENonOwner}) {
	sendPutAck;
	popRequestQueue;
    }

    // If we get another request for a block that's waiting on memory,
    // stall that request.
    transition({FI_m, E_m, F_m}, {GetS, GetMOwner, GetMNonOwner}) {
        stall;
    }
    
    transition({F_AS, FF_A}, {PutFOwnerSharer, PutFOwnerNoSharer, PutFNonOwner}) {
	stall;
    }
}
